{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5869c01c",
   "metadata": {},
   "source": [
    "# SMS Spam Classification: Detecting Unwanted Messages \n",
    "Phân loại tin nhắn rác SMS: Phát hiện tin nhắn không mong muốn - Bằng cách sử dụng model Bayes Ngây thơ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d02a7",
   "metadata": {},
   "source": [
    "## 1. Giới thiệu\n",
    "Naïve Bayes là gì?. \n",
    "- Nói một cách đơn giản, Naïve Bayes là một thuật toán Phân loại (Classification).\n",
    "- Nhiệm vụ của nó là dự đoán một đối tượng thuộc về \"lớp\" (category) nào, dựa trên các \"đặc trưng\" (features) của nó.\n",
    "- Ví dụ:\n",
    "    + Dựa trên nội dung (các từ) của một email, nó thuộc lớp \"Spam\" hay \"Không phải Spam\"?\n",
    "    + Dựa trên các triệu chứng (sốt, ho, đau đầu), bệnh nhân thuộc lớp \"Cảm cúm\" hay \"Dị ứng\"?\n",
    "- Thuật toán này hoạt động dựa trên một định lý toán học nổi tiếng gọi là Định lý Bayes (Bayes' Theorem)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8a035",
   "metadata": {},
   "source": [
    "### 1.1 Định lý Bayes\n",
    "Định lý Bayes giúp chúng ta \"lật ngược\" một câu hỏi về xác suất.\n",
    "Giả sử có 2 sự kiện A và B. Chúng ta thường dễ dàng tính được $P(B|A)$ (Xác suất xảy ra B nếu biết A đã xảy ra). Nhưng thứ chúng ta thực sự muốn biết thường là $P(A|B)$ (Xác suất xảy ra A nếu biết B đã xảy ra).\n",
    "- Định lý Bayes cho chúng ta công thức: $$P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}$$\n",
    "- Trong phân tích dữ liệu, chúng ta áp dụng công thức này như sau: $$P(\\text{Lớp} | \\text{Đặc trưng}) = \\frac{P(\\text{Đặc trưng} | \\text{Lớp}) \\times P(\\text{Lớp})}{P(\\text{Đặc trưng})}$$\n",
    "    + $P(\\text{Lớp} | \\text{Đặc trưng})$: Xác suất hậu nghiệm (Posterior). Đây là thứ ta muốn tìm. Ví dụ: \"Xác suất email này là 'Spam', biết rằng nó chứa từ 'offer' và 'free'?\"\n",
    "    + $P(\\text{Đặc trưng} | \\text{Lớp})$: Khả năng (Likelihood). Đây là thứ ta học từ dữ liệu. Ví dụ: \"Trong các email 'Spam', xác suất chứa từ 'offer' là bao nhiêu?\"\n",
    "    + $P(\\text{Lớp})$: Xác suất tiên nghiệm (Prior). Đây cũng là thứ ta học từ dữ liệu. Ví dụ: \"Trong tổng số email, xác suất một email bất kỳ là 'Spam' là bao nhiêu?\" (ví dụ: 30%).\n",
    "    + $P(\\text{Đặc trưng})$: Bằng chứng (Evidence). Xác suất để các đặc trưng này xuất hiện. (Phần này sẽ được đơn giản hóa, ta sẽ nói ở dưới)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0866f2bd",
   "metadata": {},
   "source": [
    "### 1.2 Tại sao lại gọi là \"Naïve\" (Ngây thơ)?\n",
    "Thực tế, một đối tượng có rất nhiều đặc trưng (ví dụ: một email có 100 từ). Nếu tính toán $P(\\text{Đặc trưng} | \\text{Lớp})$ (ví dụ: $P(\\text{\"offer\", \"free\", \"report\"} | \\text{Spam})$), chúng ta sẽ phải tính mối liên hệ phức tạp giữa các từ này.\n",
    "- Naïve Bayes đưa ra một giả định \"ngây thơ\": Các đặc trưng là ĐỘC LẬP với nhau, khi biết Lớp.\n",
    "- Điều này có nghĩa là: \n",
    "    + Thuật toán giả sử việc từ \"offer\" xuất hiện không ảnh hưởng gì đến việc từ \"free\" xuất hiện, miễn là chúng ta đang xét trong nhóm email \"Spam\".\n",
    "    + Trong thực tế, điều này rõ ràng là sai (hai từ này thường đi với nhau). Nhưng sự \"ngây thơ\" này lại giúp đơn giản hóa toán học một cách đáng kinh ngạc.\n",
    "- Vì giả định \"ngây thơ\" đó, công thức $P(\\text{Đặc trưng} | \\text{Lớp})$ được đơn giản hóa thành:\n",
    "    + $P(\\text{Đặc trưng 1, Đặc trưng 2, ...} | \\text{Lớp})$\n",
    "$\\approx$\n",
    "$P(\\text{Đặc trưng 1} | \\text{Lớp}) \\times P(\\text{Đặc trưng 2} | \\text{Lớp}) \\times ...$\n",
    "    + Việc tính toán $P(\\text{từ \"offer\"} | \\text{Spam})$ và $P(\\text{từ \"free\"} | \\text{Spam})$ riêng lẻ thì vô cùng dễ dàng, chỉ cần đếm tần suất.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12910179",
   "metadata": {},
   "source": [
    "### 1.3 Các loại mô hình Naïve Bayes phổ biến\n",
    "Trong thư viện scikit-learn (thư viện học máy phổ biến nhất), chúng ta có 3 loại Naïve Bayes chính. Việc dùng loại nào hoàn toàn phụ thuộc vào dạng dữ liệu (features):\n",
    "- Gaussian Naïve Bayes (GaussianNB):\n",
    "    + Dùng khi nào? Khi các đặc trưng (features) là dữ liệu liên tục (continuous) và chắc rằng chúng tuân theo phân phối Chuẩn (Gaussian), tức là hình chuông.\n",
    "    + Ví dụ: Dự đoán một người là \"Nam\" hay \"Nữ\" dựa trên chiều cao, cân nặng, cỡ giày. Đây đều là các con số thực liên tục.\n",
    "- Multinomial Naïve Bayes (MultinomialNB):\n",
    "    + Dùng khi nào? Khi các đặc trưng của là dữ liệu đếm (counts), hay nói rộng hơn là tần suất (frequencies). Dữ liệu này thường là số nguyên, không âm.\n",
    "    + Ví dụ: Chính là bài toán của chúng ta! Chúng ta đếm số lần một từ xuất hiện trong văn bản (ví dụ: từ \"free\" xuất hiện 2 lần, \"win\" xuất hiện 1 lần). Đây chính là \"Multinomial data\".\n",
    "- Bernoulli Naïve Bayes (BernoulliNB):\n",
    "    + Dùng khi nào? Khi các đặc trưng của là dữ liệu nhị phân (binary), tức là chỉ có 2 giá trị \"Có\" hoặc \"Không\" (1 hoặc 0).\n",
    "    + Ví dụ: Cũng là bài toán văn bản, nhưng ta không quan tâm số lần từ \"free\" xuất hiện. Ta chỉ quan tâm nó \"Có xuất hiện\" (1) hay \"Không xuất hiện\" (0) trong tin nhắn.\n",
    "> Trong bài test này chúng ta sẽ sử dụng mô hình thứ hai để tìm hiểu về Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce802b5",
   "metadata": {},
   "source": [
    "## 2. Tập dữ liệu SMS Spam Collection Dataset\n",
    "là một tập hợp các tin nhắn SMS được gắn thẻ đã được thu thập cho mục đích nghiên cứu SMS Spam. Bộ sưu tập này bao gồm một tập hợp 5.574 tin nhắn SMS bằng tiếng Anh, được gắn thẻ theo mức độ tin nhắn rác (ham) hoặc tin nhắn rác (spam).\n",
    "> **Nội dung:** \n",
    "- Mỗi tệp chứa một tin nhắn trên một dòng. Mỗi dòng gồm hai cột: **v1** chứa nhãn (thư rác hoặc tin nhắn rác) và **v2** chứa văn bản thô.\n",
    "- Kho dữ liệu này được thu thập từ các nguồn miễn phí hoặc miễn phí để nghiên cứu trên Internet:\n",
    "    + Một bộ sưu tập gồm 425 tin nhắn SMS rác đã được trích xuất thủ công từ trang web Grumbletext. Đây là một diễn đàn tại Anh, nơi người dùng điện thoại di động công khai khiếu nại về tin nhắn SMS rác, hầu hết đều không báo cáo chính xác tin nhắn rác nhận được. Việc xác định nội dung tin nhắn rác trong các khiếu nại là một nhiệm vụ rất khó khăn và tốn thời gian, đòi hỏi phải quét kỹ lưỡng hàng trăm trang web.\n",
    "    + Một tập hợp con gồm 3.375 tin nhắn SMS được chọn ngẫu nhiên từ Kho dữ liệu tin nhắn SMS NUS (NSC), một tập dữ liệu gồm khoảng 10.000 tin nhắn hợp lệ được thu thập cho mục đích nghiên cứu tại Khoa Khoa học Máy tính, Đại học Quốc gia Singapore. Các tin nhắn này chủ yếu đến từ người dân Singapore và phần lớn là sinh viên đang theo học tại trường. Những tin nhắn này được thu thập từ các tình nguyện viên, những người đã được thông báo rằng những đóng góp của họ sẽ được công khai. \n",
    "    + Danh sách 450 tin nhắn SMS ham được thu thập từ Luận án Tiến sĩ của Caroline \n",
    "    + Cuối cùng, chúng tôi đã tích hợp SMS Spam Corpus v.0.1 Big. Kho dữ liệu này chứa 1.002 tin nhắn SMS ham và 322 tin nhắn rác."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21adb4c2",
   "metadata": {},
   "source": [
    "### 2.1. Problem Statement\n",
    "Mục tiêu chính là phát triển một mô hình dự đoán có khả năng phân loại chính xác tin nhắn SMS đến là tin nhắn rác hay tin nhắn ham. Chúng tôi sẽ sử dụng bộ dữ liệu SMS Spam Collection, bao gồm 5.574 tin nhắn SMS được gắn nhãn tương ứng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86258c2b",
   "metadata": {},
   "source": [
    "## 3. Chuẩn bị dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe107e",
   "metadata": {},
   "source": [
    "### 3.1 Import thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2c869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kn260\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kn260\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nhóm Thư viện Phân tích Dữ liệu Cốt lõi\n",
    "import numpy as np        # Dùng cho các phép toán số học\n",
    "import pandas as pd       # Dùng để xử lý dữ liệu dạng bảng\n",
    "import matplotlib.pyplot as plt  # Dùng để trực quan hóa dữu liệu\n",
    "%matplotlib inline\n",
    "\n",
    "# Nhóm Thư viện Xử lý Văn bản\n",
    "from wordcloud import WordCloud\n",
    "# Đây là một thư viện thú vị dùng để tạo ra Đám mây từ (Word Cloud). Nó sẽ vẽ một hình ảnh, trong đó các từ xuất hiện nhiều nhất trong văn bản sẽ được hiển thị to nhất. \n",
    "# Đây là cách trực quan hóa nhanh để biết chủ đề chính của một đoạn văn bản.\n",
    "\n",
    "\n",
    "# Importing NLTK for natural language processing\n",
    "import nltk # NLTK (Natural Language Toolkit) là một trong những thư viện lâu đời và toàn diện nhất cho NLP. \n",
    "# Nó cung cấp vô số công cụ để \"dạy\" máy tính hiểu ngôn ngữ của con người.\n",
    "from nltk.corpus import stopwords   \n",
    "# Stopwords (Từ dừng) là những từ phổ biến nhưng không mang nhiều ý nghĩa (ví dụ: \"và\", \"là\", \"của\", \"thì\", \"a\", \"the\", \"is\"...). \n",
    "# Trong phân tích văn bản, chúng ta thường sẽ loại bỏ chúng đi để tập trung vào các từ khóa quan trọng.\n",
    "\n",
    "# Tải về Tài nguyên NLTK\n",
    "nltk.download('stopwords')\n",
    "# Lệnh này tải về danh sách các từ dừng (stopwords) cho nhiều ngôn ngữ (bao gồm cả tiếng Anh) từ máy chủ của NLTK. \n",
    "# Nếu không có danh sách này, NLTK sẽ không biết từ nào là từ dừng để mà loại bỏ.\n",
    "nltk.download('punkt')       \n",
    "# Lệnh này tải về một mô hình gọi là \"Punkt Tokenizer\".\n",
    "# Tokenization (Tách từ) là quá trình cơ bản nhất trong NLP: chia một câu hoặc một đoạn văn thành các từ (token) riêng lẻ.\n",
    "# Ví dụ: \"Em chào thầy.\" $\\rightarrow$ ['Em', 'chào', 'thầy', '.']. \"Punkt\" là một mô hình đã được huấn luyện để làm việc này một cách thông minh, xử lý tốt các dấu câu phức tạp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25c52984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8083b1",
   "metadata": {},
   "source": [
    "### 3.2 Tải tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a966ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/spam.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17da7fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73982a10",
   "metadata": {},
   "source": [
    "Với tập dataset. Ta có:\n",
    "- v1: Biến phân loại **ham** và **spam**\n",
    "- v2: Nội dung email\n",
    "- Unnamed: 2, Unnamed: 3, Unnamed: 4: Là những giá trị NaN. Cần loại bỏ trước khi đưa vào mô hình học máy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa0c647",
   "metadata": {},
   "source": [
    "### 3.3 Xử lý dữ liệu trước khi xây dựng mô hình từ dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4533b27d",
   "metadata": {},
   "source": [
    "Sau khi có dữ liệu sạch, chúng ta sẽ bắt đầu bước Phân tích Khám phá (EDA) và Tiền xử lý văn bản"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc30134",
   "metadata": {},
   "source": [
    "3 cột Unnamed: 2, Unnamed: 3, và Unnamed: 4 hầu như chỉ chứa giá trị NaN (rỗng). Chúng ta không cần chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8079c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns with NaN values\n",
    "data = df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d70331",
   "metadata": {},
   "source": [
    "Tên cột v1 (nhãn) và v2 (tin nhắn) rất khó hiểu. Chúng ta nên đổi tên chúng để code dễ đọc hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cdd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity:\n",
    "data.columns = ['label', 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c50f11",
   "metadata": {},
   "source": [
    "Dữ liệu sau khi đã chuẩn hóa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ba2fd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c12af73",
   "metadata": {},
   "source": [
    "## 4. Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed424700",
   "metadata": {},
   "source": [
    "### 4.1 Phân phối tập dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51909064",
   "metadata": {},
   "source": [
    "- Sau khi làm sạch dữ liệu. Chia dữ liệu thành 2 tập, tập huấn luyện và tập kiểm tra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ee99a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target labels (y)\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1046bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee51436c",
   "metadata": {},
   "source": [
    "### 4.2 Xây dựng vector hóa nội dung HAM | SPAM của tập train và tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0763e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "# Nó hoạt động y như tên gọi: chỉ đơn giản là đếm số lần mỗi từ xuất hiện trong mỗi câu.\n",
    "\n",
    "# Fit and transform the training data (X_train)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train['text'])\n",
    "# Gồm 2 hành động:\n",
    "#   fit (Học): \"Học\" toàn bộ từ vựng (tạo ra các cột call, free, money...) chỉ từ dữ liệu huấn luyện (X_train).\n",
    "#   transform (Biến đổi): Biến đổi X_train thành ma trận số dựa trên từ vựng vừa học.\n",
    "\n",
    "# Transform the test data (X_test)\n",
    "X_test_vectorized = vectorizer.transform(X_test['text'])\n",
    "# Gồm 1 hành động:\n",
    "#   transform (Biến đổi): Biến đổi X_test thành ma trận số dựa trên từ vựng đã học từ X_train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c70ae2",
   "metadata": {},
   "source": [
    "> Tại sao không fit nữa? Đây là mấu chốt: X_test là \"đề thi\". Em không được phép \"học\" bất cứ thông tin gì từ \"đề thi\" (kể cả từ vựng của nó). Nếu một từ trong X_test mà chưa từng có trong X_train, nó sẽ bị bỏ qua. Điều này mô phỏng chính xác cách mô hình hoạt động trong thực tế."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f9f628",
   "metadata": {},
   "source": [
    "### 4.3 Xây dựng mô hình Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23939e3d",
   "metadata": {},
   "source": [
    "Chúng ta sẽ dùng MultinomialNB (Naïve Bayes Đa thức), loại này rất phù hợp cho bài toán đếm từ và TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98d87a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4d8316",
   "metadata": {},
   "source": [
    "- naive_bayes thuật toán Bayes lấy từ sklearn \n",
    "- Tại sao là MultinomialNB? \"Multinomial\" có nghĩa là \"đa thức\"\n",
    "- Đây là phiên bản Naïve Bayes được thiết kế đặc biệt để làm việc với dữ liệu dạng đếm (counts).\n",
    "    + Khi dùng CountVectorizer ở bước trước, chúng đã tạo ra một ma trận đếm số lần mỗi từ xuất hiện (ví dụ: từ \"free\" xuất hiện 2 lần, từ \"call\" xuất hiện 1 lần).\n",
    "    + MultinomialNB là mô hình để học từ loại dữ liệu \"đếm\" này. (Có một loại khác là GaussianNB dùng cho dữ liệu liên tục như chiều cao, cân nặng, và BernoulliNB dùng cho dữ liệu nhị phân có/không).\n",
    "- **classifier = MultinomialNB():**\n",
    "    + Đây là lệnh khởi tạo (instantiation) một đối tượng.\n",
    "    + classifier bây giờ là một \"bộ não\" Naïve Bayes. Nó đã có sẵn mọi công thức toán học bên trong, nhưng nó chưa biết bất cứ điều gì về \"spam\" hay \"ham\". Nó là một mô hình \"chưa được huấn luyện\" (untrained model).\n",
    "- **classifier.fit(X_train_vectorized, y_train):** Đây là lệnh huấn luyện (training), hay còn gọi là \"fit\" mô hình. Đây là bước quan trọng nhất.\n",
    "    + X_train_vectorized: Đây là dữ liệu đầu vào (features). Nó là cái ma trận số khổng lồ (từ CountVectorizer) cho biết từ nào xuất hiện bao nhiêu lần trong mỗi tin nhắn của tập huấn luyện.\n",
    "    + y_train: Đây là nhãn (labels) hay đáp án. Nó là danh sách các số 0 (ham) và 1 (spam) tương ứng với từng tin nhắn trong X_train_vectorized.\n",
    "- Khi chạy lệnh fit, mô hình classifier sẽ làm 2 việc chính:\n",
    "    + Học Xác suất Tiên nghiệm $P(\\text{Lớp})$: Nó đếm xem trong y_train có bao nhiêu % là \"spam\" và bao nhiêu % là \"ham\". Ví dụ, nếu có 100 tin nhắn mà 20 tin là spam, nó sẽ học được $P(\\text{spam}) = 0.2$ và $P(\\text{ham}) = 0.8$.\n",
    "    + Học Xác suất Khả năng (Likelihood) $P(\\text{Từ} | \\text{Lớp})$: Đây là phần chính. Nó sẽ xem xét tất cả các từ trong từ vựng và tính:\n",
    "        - $P(\\text{\"free\"} | \\text{spam})$: Trong số các tin nhắn \"spam\", xác suất gặp từ \"free\" là bao nhiêu? (Chắc chắn sẽ cao).\n",
    "        - $P(\\text{\"free\"} | \\text{ham})$: Trong số các tin nhắn \"ham\", xác suất gặp từ \"free\" là bao nhiêu? (Chắc chắn sẽ thấp).\n",
    "        - ...tương tự cho mọi từ khác\n",
    "> Nó đã trở thành một mô hình đã được huấn luyện (trained model). Nó đã học và lưu trữ tất cả các xác suất $P(\\text{spam})$ và $P(\\text{Từ} | \\text{Lớp})$ này."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1460b2de",
   "metadata": {},
   "source": [
    "## 5 Đánh giá hiệu quả của mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49c571c",
   "metadata": {},
   "source": [
    "### 5.1 Ý tưởng của việc Đánh giá\n",
    "- Dữ liệu để học (Tập Train - 80%): huấn luyện mô hình X_train (\"sách giáo khoa\") và y_train (\"đáp án\" trong sách) để nó học. Mô hình đã \"thuộc lòng\" bộ dữ liệu này.\n",
    "- Dữ liệu để thi (Tập Test - 20%): giữ lại X_test (\"đề thi\") và y_test (\"đáp án\" của đề thi). Đây là dữ liệu mà mô hình chưa bao giờ thấy.\n",
    "- Làm bài thi: yêu cầu mô hình (classifier) đưa ra dự đoán (.predict()) cho X_test. Kết quả này ta gọi là y_pred (\"bài làm\" của mô hình).\n",
    "- Chấm bài: Bước cuối cùng là lấy \"bài làm\" (y_pred) ra, so sánh từng câu với \"đáp án\" (y_test) để xem nó đúng hay sai, và sai ở đâu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0869181",
   "metadata": {},
   "source": [
    "### 5.2 Code thực thi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d54b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Confusion Matrix:\n",
      "[[963   2]\n",
      " [ 16 134]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       965\n",
      "        spam       0.99      0.89      0.94       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.95      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report \n",
    "# Thư viện accuracy_score, confusion_matrix và classification_report từ sklearn.metrics cung cấp các công cụ để đánh giá hiệu suất của mô hình học máy.\n",
    "\n",
    "# Bắt đầu lấy dữ liệu test để dự đoán\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "# Kết quả y_pred sẽ là một danh sách các số 0 (Ham) và 1 (Spam) mà mô hình dự đoán cho từng tin nhắn trong X_test.\n",
    "\n",
    "# Đánh giá độ chính xác của mô hình\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# Tính toán độ chính xác bằng cách so sánh nhãn thực tế (y_test) với nhãn dự đoán (y_pred).\n",
    "\n",
    "# Đánh giá chi tiết hơn\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# Tạo ma trận nhầm lẫn (confusion matrix) để xem mô hình đã phân loại đúng và sai như thế nào.\n",
    "# Ma trận này sẽ cho biết số lượng tin nhắn Ham và Spam được dự đoán\n",
    "\n",
    "# Đây là một \"bảng điểm tổng hợp\" tự động tính toán từ cái confusion_matrix ở trên.\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c054d",
   "metadata": {},
   "source": [
    "- **Phân tích output:**\n",
    "- **Accuracy:** Mô hình đã dự đoán đúng 98% tin nhắn\n",
    "- **Confusion Matrix:**\n",
    "$$  \\begin{bmatrix}\n",
    "    \\text{TN} & \\text{FP} \\\\\n",
    "    \\text{FN} & \\text{TP}\n",
    "  \\end{bmatrix}$$\n",
    "  + Trong bài toán Spam (0=Ham, 1=Spam):\n",
    "    - TN (True Negative - trên trái): Số tin Ham (0) được dự đoán đúng là Ham (0). $\\rightarrow$ Tốt!\n",
    "    - TP (True Positive - dưới phải): Số tin Spam (1) được dự đoán đúng là Spam (1). $\\rightarrow$ Tốt!\n",
    "    - FP (False Positive - trên phải): Số tin Ham (0) bị dự đoán nhầm là Spam (1). $\\rightarrow$ Rất tệ! Đây là lỗi Loại I, email quan trọng của bị vứt vào thùng rác.\n",
    "    - FN (False Negative - dưới trái): Số tin Spam (1) bị dự đoán nhầm là Ham (0). $\\rightarrow$ Tệ vừa! Đây là lỗi Loại II, bị lọt thư rác.\n",
    "- **Classification Report:**\n",
    "  + Precision (Độ chuẩn xác):\n",
    "    - $Precision = TP / (TP + FP)$\n",
    "    - Ý nghĩa (cho lớp Spam): Trong tất cả các tin nhắn mà mô hình gán nhãn là \"Spam\", có bao nhiêu % thực sự là \"Spam\"?\n",
    "    - Mục tiêu: Ta muốn Precision cao. Precision cao nghĩa là mô hình ít mắc lỗi FP (ít ném nhầm thư thật vào thùng rác).\n",
    "  + Recall (Độ phủ / Độ nhạy):\n",
    "    - $Recall = TP / (TP + FN)$\n",
    "    - Ý nghĩa (cho lớp Spam): Trong tất cả các tin nhắn thực sự là \"Spam\", mô hình phát hiện (bắt) được bao nhiêu %?\n",
    "    - Mục tiêu: Ta muốn Recall cao. Recall cao nghĩa là mô hình ít mắc lỗi FN (ít bỏ lọt thư rác).\n",
    "  + F1-Score:\n",
    "    - Là trung bình điều hòa của Precision và Recall. Nó là một chỉ số cân bằng, giúp đánh giá tổng thể khi Precision và Recall trái ngược nhau.\n",
    "  + Support là số lượng mẫu (samples) thực tế thuộc về lớp đó trong tập dữ liệu test.\n",
    "    - Nó giúp phát hiện ra Dữ liệu Mất cân bằng (Imbalanced Data). Chúng ta thấy ngay tỉ lệ Ham (966) nhiều hơn Spam (149) gấp ~6.5 lần. Khi dữ liệu mất cân bằng, chỉ số Accuracy (98%) có thể gây hiểu nhầm, và đó là lý do chúng ta phải xem xét kỹ Precision và Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bfe08d",
   "metadata": {},
   "source": [
    "# Kết thúc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
